from __future__ import annotations

import base64
import json
import mimetypes
import os
from pathlib import Path
from typing import TYPE_CHECKING

import click
from openai import OpenAI
from openai.types.responses import ResponseInputImageParam, ResponseInputTextParam
from openai.types.responses.response_input_param import Message
from PIL import Image

if TYPE_CHECKING:
    from .config import Config


def get_image_description(
    client: OpenAI, image_path: Path, context: str, model: str = "gpt-4.1-nano"
) -> str:
    """
    Send an image to OpenAI via the Responses API and return its description.

    Args:
        client: An OpenAI client instance.
        image_path: Path to the image file.
        context: User-provided context string.
        model: OpenAI model to use.

    Returns:
        The text description returned by the model.

    AI: Generated by ChatGPT
    """
    img_bytes = image_path.read_bytes()
    mime, _ = mimetypes.guess_type(str(image_path))
    if mime is None:
        raise ValueError(f"Cannot determine MIME type for {image_path}")
    b64 = base64.b64encode(img_bytes).decode("ascii")

    # Build the prompt and embed the image
    prompt = (
        f"Context: {context}\n\n"
        f"Filename: {image_path.name}\n\n"
        "Describe the image given the context and filename."
        "Description should be concise and appropriate for image alt text."
    )

    response = client.responses.create(
        model=model,
        max_output_tokens=256,
        input=[
            Message(
                role="user",
                content=[
                    ResponseInputTextParam(type="input_text", text=prompt),
                    ResponseInputImageParam(
                        type="input_image",
                        image_url=f"data:{mime};base64,{b64}",
                        detail="auto",
                    ),
                ],
            )
        ],
    )
    return response.output_text.strip()


def write_sidecar(image_path: Path, description: str) -> None:
    sidecar_data = {"ImageDescription": description}
    with image_path.with_suffix(f"{image_path.suffix}.meta").open("w") as f:
        json.dump(sidecar_data, f)


def embed_exif_description(image_path: Path, description: str) -> None:
    """
    Write a description string into an image's EXIF ImageDescription using Pillow.

    Args:
        image_path: Path to the image file.
        description: Description text to embed.

    Raises:
        OSError if saving fails.

    AI: Generated by ChatGPT
    """
    with Image.open(image_path) as img:
        exif = img.getexif()
        # EXIF tag 270 is ImageDescription
        exif[270] = description
        exif_bytes = exif.tobytes()
        img.save(image_path, exif=exif_bytes)


def process_directory(client: OpenAI, directory: Path, context: str) -> None:
    """
    Find all supported images under `directory` and annotate them.

    Args:
        client: An OpenAI client instance.
        directory: Root directory to search.
        context: Context string for all images.

    AI: Generated by ChatGPT
    """
    supported_exts = {".jpg", ".jpeg", ".png", ".webp"}
    for root, _, files in os.walk(directory):
        for fname in files:
            if Path(fname).suffix.lower() in supported_exts:
                img_path = Path(root) / fname
                if img_path.with_suffix(f"{img_path.suffix}.meta").exists():
                    print(f"Skipping {img_path}, metadata already exists…")
                    continue
                print(f"Processing {img_path}…")
                try:
                    desc = get_image_description(client, img_path, context)
                    print(f"  ✅ Description: {desc}")
                    write_sidecar(img_path, desc)
                except Exception as e:
                    print(f"  ❌ Error on {img_path}: {e}")
                    raise


@click.command()
@click.argument("directory", type=Path)
@click.option("--context", "-c", help="Context for this batch of images")
@click.pass_obj
def describe_images(
    config: Config, directory: Path, context: str | None = None
) -> None:
    if not directory.is_dir():
        print(f"{directory} is not a directory")
        return

    if context is None:
        context = click.prompt(
            "Enter context for this batch of images:", default=""
        ).strip()
        if not context:
            print("No context provided; exiting.")
            return

    # Initialize OpenAI client using passed configuration
    api_key = config.tokens.openai.open
    client = OpenAI(api_key=api_key)

    process_directory(client, directory, context)
    print("Done.")


if __name__ == "__main__":
    describe_images()
