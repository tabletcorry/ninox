from __future__ import annotations

import base64
import mimetypes
import os
from pathlib import Path

import click
from openai import OpenAI
from openai.types.responses import ResponseInputImageParam, ResponseInputTextParam
from openai.types.responses.response_input_param import Message
from PIL import Image


def get_image_description(
    client: OpenAI, image_path: Path, context: str, model: str = "gpt-4.1-nano"
) -> str:
    """
    Send an image to OpenAI via the Responses API and return its description.

    Args:
        client: An OpenAI client instance.
        image_path: Path to the image file.
        context: User-provided context string.
        model: OpenAI model to use.

    Returns:
        The text description returned by the model.

    AI: Generated by ChatGPT
    """
    # Read and encode the image
    img_bytes = image_path.read_bytes()
    mime, _ = mimetypes.guess_type(str(image_path))
    if mime is None:
        raise ValueError(f"Cannot determine MIME type for {image_path}")
    b64 = base64.b64encode(img_bytes).decode("ascii")

    prompt = (
        f"Context: {context}\n\n"
        "Describe the image given the context. "
        "Description should be short and concise and appropriate for image alt text."
    )

    # Use the Responses API
    response = client.responses.create(
        model=model,
        input=[
            Message(
                role="user",
                content=[
                    ResponseInputTextParam(type="input_text", text=prompt),
                    ResponseInputImageParam(
                        type="input_image",
                        image_url=f"data:{mime};base64,{b64}",
                        detail="auto",
                    ),
                ],
            )
        ],
    )
    return response.output_text.strip()


def embed_exif_description(image_path: Path, description: str) -> None:
    """
    Write a description string into an image's EXIF ImageDescription using Pillow.

    Args:
        image_path: Path to the image file.
        description: Description text to embed.

    Raises:
        OSError if saving fails.

    AI: Generated by ChatGPT
    """
    with Image.open(image_path) as img:
        exif = img.getexif()
        # EXIF tag 270 is ImageDescription
        exif[270] = description
        exif_bytes = exif.tobytes()
        img.save(image_path, exif=exif_bytes)


def process_directory(client: OpenAI, directory: Path, context: str) -> None:
    """
    Find all supported images under `directory` and annotate them.

    Args:
        client: An OpenAI client instance.
        directory: Root directory to search.
        context: Context string for all images.

    AI: Generated by ChatGPT
    """
    supported_exts = {".jpg", ".jpeg", ".png", ".webp"}
    for root, _, files in os.walk(directory):
        for fname in files:
            if Path(fname).suffix.lower() in supported_exts:
                img_path = Path(root) / fname
                print(f"Processing {img_path}…")
                try:
                    desc = get_image_description(client, img_path, context)
                    embed_exif_description(img_path, desc)
                except Exception as e:
                    print(f"  ❌ Error on {img_path}: {e}")
                    raise


@click.command()
@click.argument("directory", type=Path)
def describe_images(directory: Path) -> None:
    """
    Parse arguments, prompt for context, initialize client, and run processing.

    AI: Generated by ChatGPT
    """
    if not directory.is_dir():
        print(f"{directory} is not a directory")
        return

    context = click.prompt("Enter context for this batch of images: ").strip()
    if not context:
        print("No context provided; exiting.")
        return

    # Initialize OpenAI client (requires OPENAI_API_KEY env var)
    client = OpenAI()

    process_directory(client, directory, context)
    print("Done.")
